{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL-TIME HANDWIRITNG RECOGNITION USING TENSORFLOW AND RASPBERRY PI\n",
    "Prepared By: Luis Rivera\n",
    "\n",
    "In partial fulfillment of the requirements for CPE 4903\n",
    "\n",
    "May 02, 2023\n",
    "\n",
    "Kennesaw State University"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Introduction\n",
    "2. Theory\n",
    "    1. MNIST Dataset\n",
    "    2. Training\n",
    "    3. Testing\n",
    "     \n",
    "     \n",
    "3. Procedure/Design\n",
    "    1. Training\n",
    "    2. Testing \n",
    "     \n",
    "     \n",
    "4. Data and Analysis\n",
    "    1. Training Results\n",
    "     \n",
    " \n",
    "5. Conclusion\n",
    "6. Evidence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "        The following report will detail my work to create and test a convolutional neural network that can identify handwritten numbers captured in real time with a raspberry pi camera. It will describe the theory behind the components as well as detail the specific implementations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "### 1. MNIST Dataset\n",
    "\n",
    "        In order to train a neural network to recognize handwritten numbers, we need a large set of such handwritten numbers. Our starting point is the MNIST database (Modified National Institute of Standards and Technology database). This collection of 28 x 28 pixel grayscale images was compiled for the sole purpose of training a neural network like our own. It will save us a lot of time.\n",
    "\n",
    "### 2. Training\n",
    "\n",
    "        To train this model, we will use a Convolutional Neural Network, which is designed for training on 2-dimensional images. It is precisely what we need for our normalized collection of handwritten numbers provided by MNIST. We use Keras to train and analyze a pretty simple model. We determine the success of training by splitting the dataset into train and test sets and test the accuracy of the model trained with part of the set by comparing it with the unseen part of the set. The goal is to have a model accurate in the upper 90% range.\n",
    "\n",
    "### 3. Testing\n",
    "\n",
    "        We plan to test our model on real handwritten numbers in real time with a camera. In our case we are using a raspberry pi with camera. Generally, we will initialize a video capture, and, for every frame, process the image to be appropriate for input into our model predictor and report the predicted character and it's confidence in that prediction. We are aiming for a confidence greater than 50%.\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure/Design\n",
    "\n",
    "### 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we load and process the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the model and it's layers here. We are using 2 layers of Conv2D. I originally had many large dense relu layers after the Conv2D, but it was determined late that large relu layers before the softmax output will result in artificially large weights that distort the confidence of the prediction. Even without these dense layers, we achieve a >98% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (2, 2), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Conv2D(32, (2, 2), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually train the model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can evaluate the model and plot the accuracy and loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss & accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be using the model in another script and we do not want to retrain the model everytime, we will save the model to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/pi/handrecog/keras_convnet_adam')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sense_hat import SenseHat\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by initializing our sense hat to display our prediction later, as well as load our saved model and begin a video capture. The count variable here count the number of frame that are analyzed in the following loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense = SenseHat()\n",
    "\n",
    "loaded_model = tf.keras.models.load_model('/home/pi/handrecog/keras_convnet_adam')\n",
    "\n",
    "loaded_model.summary()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "count = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main loop of the program. In each loop, a frame of video is captured and displayed so that you can view the feed in real time. The image is then inverted, resized to 28 x 28, converted from bgr to rgb, converted to a tensor, normalized to values 0-255, converted to grayscale, and a column is added for model input. After all this processing, we call the prediction function with our single image as the input. This returns an array of predictions for each number. The predictions are the probability that each number is correct and all add up to 1.0. We find our actual predicted nuumber by finding the number with the greatest probability. The model's confidence is the highjest predicted probability. I chose to only display a prediction if the confidence is greater than or equal to 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    ret, raw_bgr = cap.read()\n",
    "    gray = cv2.cvtColor(raw_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame', gray)\n",
    "    bgr_inverted = cv2.threshold(raw_bgr, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "    resized_bgr = cv2.resize(bgr_inverted[1], (28, 28), interpolation = cv2.INTER_CUBIC)\n",
    "    rgb = cv2.cvtColor(resized_bgr, cv2.COLOR_BGR2RGB)\n",
    "    rgb_tensor = (tf.convert_to_tensor(rgb, dtype=tf.float32) / 255.0)\n",
    "    gray_tensor = tf.image.rgb_to_grayscale(rgb_tensor)\n",
    "    cv2.imwrite(\"preview.jpg\", gray_tensor.numpy())\n",
    "    gray_tensor = tf.expand_dims(gray_tensor, axis=0)\n",
    "\n",
    "    y_hat = loaded_model.predict(gray_tensor)\n",
    "\n",
    "    prediction= np.argmax(y_hat)\n",
    "    score = y_hat[[0],[prediction]].item()\n",
    "\n",
    "    if score >= 0.7:\n",
    "        print('Number is a {} with a certainty of {:.2%}'.format(prediction, score))\n",
    "        sense.show_letter(str(prediction))\n",
    "    else:\n",
    "        if count % 2:\n",
    "            sense.show_letter('/')\n",
    "        else:\n",
    "            sense.show_letter('\\\\')\n",
    "        count = count + 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important quantifiable metrics for our model are the loss and accuracy of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Name|Value|\n",
    "|----|-----|\n",
    "|Model Training Loss|0.0703|\n",
    "|Model Training Accuracy|0.9798|\n",
    "|Model Test Loss|0.0632|\n",
    "|Model Test Accuracy|0.9808|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        In conclusion, I am very pleased with the resulting product of this project. I was able to build a CNN model and raspberry pi application that quickly and accurately identify handwritten numbers. More than just make working software, I was able to work between multiple platoforms and successfully integrate hardware and software into a cohesive system. I beleive this project to be a resounding success."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Proof of installation](Screenshot%202023-05-02%20170241.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Proof of Training](Screenshot%202023-05-02%20171857.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
